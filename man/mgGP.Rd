% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mgGP.R
\name{mgGP}
\alias{mgGP}
\title{mgGP: mesh-grouped Gaussian process emulator for partial differential equation systems.}
\usage{
mgGP(
  X,
  Y,
  S,
  VI.settings = list(maxit = 100, K = 10, reltol = sqrt(.Machine$double.eps)),
  priors.para = list(alpha0 = 0.5, R0 = NULL, mu0 = NULL, v0 = NULL, W0 = NULL),
  GP.settings = list(nu = 2.5, g = sqrt(.Machine$double.eps), theta.init = 0.1,
    theta.lower = sqrt(.Machine$double.eps), theta.upper = 100),
  parallel = FALSE,
  n.cores = detectCores(),
  trace = FALSE
)
}
\arguments{
\item{X}{matrix designs, one per row, or list with elements:}

\item{Y}{vector of all observations. If using a list with \code{X}, \code{Z} has to be ordered with respect to \code{X0}, and of length \code{sum(mult)}}

\item{S}{upper bound and lower bound of the calibration parameter(s).}

\item{VI.settings}{optional list specifying starting values for MLE optimization, with elements:
\itemize{
 \item \code{maxit} initial value of the theta parameters to be optimized over (default to 10\% of the range determined with \code{lower} and \code{upper})
 \item \code{K=10} initial value of the nugget parameter to be optimized over (based on the variance at replicates if there are any, else \code{0.1})
 \item \code{reltol} initial value of the calibration parameter to be optimized over (default to the average of \code{cpara_max} and \code{cpara_min})
}}

\item{priors.para}{optional list specifying starting values for MLE optimization, with elements:
\itemize{
 \item \code{alpha0=0.5} initial value of the theta parameters to be optimized over (default to 10\% of the range determined with \code{lower} and \code{upper})
 \item \code{R0=NULL} initial value of the nugget parameter to be optimized over (based on the variance at replicates if there are any, else \code{0.1})
 \item \code{mu0=NULL} initial value of the calibration parameter to be optimized over (default to the average of \code{cpara_max} and \code{cpara_min})
 \item \code{v0=NULL} initial value of the calibration parameter to be optimized over (default to the average of \code{cpara_max} and \code{cpara_min})
 \item \code{W0=NULL} initial value of the calibration parameter to be optimized over (default to the average of \code{cpara_max} and \code{cpara_min})
}}

\item{GP.settings}{optional list specifying starting values for MLE optimization, with elements:
\itemize{
 \item \code{nu=2.5} initial value of the theta parameters to be optimized over (default to 10\% of the range determined with \code{lower} and \code{upper})
 \item \code{g=sqrt(.Machine$double.eps)} initial value of the nugget parameter to be optimized over (based on the variance at replicates if there are any, else \code{0.1})
 \item \code{theta.init=0.1} initial value of the calibration parameter to be optimized over (default to the average of \code{cpara_max} and \code{cpara_min})
 \item \code{theta.lower=sqrt(.Machine$double.eps)} initial value of the calibration parameter to be optimized over (default to the average of \code{cpara_max} and \code{cpara_min})
 \item \code{theta.upper=100} initial value of the calibration parameter to be optimized over (default to the average of \code{cpara_max} and \code{cpara_min})
}}

\item{trace=FALSE}{optional matrix of known boundaries in original input space, of size 2 times \code{ncol(X)}. This is only effective when \code{orthogonal=TRUE}. The default is \code{NULL} which uses the maximum and minimum values of \code{X}.}

\item{lower, upper}{optional bounds for the \code{theta} parameter (see \code{\link[hetGP]{cov_gen}} for the exact parameterization).
In the multivariate case, it is possible to give vectors for bounds (resp. scalars) for anisotropy (resp. isotropy)}

\item{known}{optional list of known parameters, e.g., \code{theta} or \code{g}}

\item{covtype}{covariance kernel type, either 'Gaussian', 'Matern5_2' or 'Matern3_2', see \code{\link[hetGP]{cov_gen}}}

\item{maxit}{maximum number of iteration for L-BFGS-B of \code{\link[stats]{optim}}}

\item{eps}{jitter used in the inversion of the covariance matrix for numerical stability}

\item{settings}{list with argument \code{return.Ki}, to include the inverse covariance matrix in the object for further use (e.g., prediction).}

\item{orthogonal}{logical. If \code{TRUE}, an orthogonal Gaussian process will be used to model the model discrepancy, otherwise a standard Gaussian process will be used.}

\item{f.sim}{a function indicating a computer model, where the input should include both input variables, \code{X}, and calibration parameter(s), \code{cpara}.}

\item{df.sim}{a function indicating the gradient of \code{f.sim}. The default is \code{NULL}, which approximates the gradient numerically by \code{\link[rootSolve]{gradient}}}

\item{MC.num}{a number indicating how many monte carlo samples are used to approximate a orthogonal kernel. . This is only effective when \code{orthogonal=TRUE}. The default is \code{NULL} which uses the rule of 30*\code{ncol(X)}.}
}
\value{
a list which is given the S3 class "\code{HomCalibrate}", with elements:
\itemize{
\item \code{theta}: maximum likelihood estimate of the lengthscale parameter(s),
\item \code{g}: maximum likelihood estimate of the nugget variance,
\item \code{trendtype}: either "\code{SK}" if \code{beta0} is given, else "\code{OK}"
\item \code{beta0}: estimated trend unless given in input,
\item \code{nu_hat}: plugin estimator of the variance,
\item \code{ll}: log-likelihood value,
\item \code{X0}, \code{Z0}, \code{Z}, \code{mult}, \code{eps}, \code{covtype}: values given in input,
\item \code{call}: user call of the function
\item \code{used_args}: list with arguments provided in the call
\item \code{nit_opt}, \code{msg}: \code{counts} and \code{msg} returned by \code{\link[stats]{optim}}
\item \code{Ki}: inverse covariance matrix (not scaled by \code{nu_hat}) (if \code{return.Ki} is \code{TRUE} in \code{settings})
\item \code{time}: time to train the model, in seconds.
\item \code{cpara} maximum likelihood estimate of the calibration parameter(s)
\item \code{orthogonal} \code{orthogonal}
\item \code{f.sim} \code{f.sim}
\item \code{df.sim} \code{df.sim}
\item \code{MC.num} \code{MC.num}
\item \code{inputBounds} \code{inputBounds}

}
}
\description{
mgGP: mesh-grouped Gaussian process emulator for partial differential equation systems
}
\details{
This code performs model calibration for inexact computer model under homoskedastic noise with multiple replicates. This code is modified from the source code of \code{\link[hetGP]{mleHomGP}}. We refer more details of the function to \code{\link[hetGP]{mleHomGP}}.
}
\examples{
\dontrun{
library(mgGP)
set.seed(1)

##### setting #####
# example: Poisson equation simulations 
# (data was generated by finite element methods via MATLAB)
X <- read.csv(system.file("extdata", "X.csv", package = "mgGP"))
Y <- read.csv(system.file("extdata", "Y.csv", package = "mgGP"))
S <- read.csv(system.file("extdata", "S.csv", package = "mgGP"))

print(dim(X)) # sample size is 5; one input variable
print(dim(S)) # 2-dimensional mesh; 401 mesh nodes
print(dim(Y)) # sample size is 5; 401 outputs at mesh nodes
# visualize two training examples
pde.plot <- function(u, nodes, ...){
  out <- as.image(u, x = t(nodes), nrow=128, ncol=128) 
  dx <- out$x[2] - out$x[1] 
  dy <- out$y[2] - out$y[1] 
  out <- image.smooth(out$z, dx=dx, dy=dy, theta=.25) 
  image.plot(x = out$x, y = out$y, z = out$z, ...)
}

par(mfrow=c(1,2))
pde.plot(Y[,1], S, main=paste("x =", X[1,1]))
pde.plot(Y[,5], S, main=paste("x =", X[5,1]))

# model fitting
fit <- mgGP(X,Y,S)
print(fit$time.elapsed) # the time elapsed

# model fitting (with parallel computing)
fit <- mgGP(X,Y,S, parallel=TRUE)
print(fit$time.elapsed) # the time elapsed
}
}
\references{
M. Binois, Robert B. Gramacy, M. Ludkovski (2018), Practical heteroskedastic Gaussian process modeling for large simulation experiments,
Journal of Computational and Graphical Statistics, 27(4), 808--821.\cr
Preprint available on arXiv:1611.05902. \cr \cr
}
\seealso{
\code{\link[HetCalibrate]{predict.homCalibrate}} for predictions.
}
