% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mcGP.R
\name{mcGP}
\alias{mcGP}
\title{mcGP: mesh-clustered Gaussian process emulator for partial differential equation systems.}
\usage{
mcGP(
  X,
  Y,
  S,
  VI.settings = list(maxit = 100, K = 10, reltol = sqrt(.Machine$double.eps)),
  priors.para = list(alpha0 = 1, R0 = NULL, mu0 = NULL, v0 = NULL, W0 = NULL),
  GP.settings = list(nu = 2.5, g = sqrt(.Machine$double.eps), theta.init = 0.1,
    theta.lower = sqrt(.Machine$double.eps), theta.upper = 100),
  parallel = FALSE,
  n.cores = parallelly::availableCores(),
  trace = FALSE
)
}
\arguments{
\item{X}{an \code{n times p} matrix specifying the input data, where \code{n} is sample size and \code{p} is number of predictors.}

\item{Y}{an \code{N times n} matrix specifying the outputs at the \code{N} mesh coordinates, where \code{N} is the number of mesh nodes.}

\item{S}{an \code{N times n} matrix specifying the mesh coordinates.}

\item{VI.settings}{a list specifying settings for the variational inference algorithm:
\itemize{
 \item \code{maxit} maximum number of iteration for variational inference; the default is 100.
 \item \code{K} maximum number of clusters; the default is 10.
 \item \code{reltol} Relative convergence tolerance. The algorithm stops if it is unable to reduce the value by a factor of \code{reltol * (abs(val) + reltol)} at a step. Defaults to \code{sqrt(.Machine$double.eps)}, typically about \code{1e-8}.
}}

\item{priors.para}{a list specifying prior hyperparameters:
\itemize{
 \item \code{alpha0} a scalar specifying concentration parameter for Dirichlet process; the default is 1.
 \item \code{mu0} a vector of length \code{d} specifying the mean of the normal prior for the mean of node coordinates; the default is the sample average of the node coordinates.
 \item \code{R0} a \code{d times d} matrix specifying the inverse covariance of the normal prior for the mean of node coordinates; the default is the sample inverse covariance of the node coordinates.
 \item \code{v0} a scalar specifying the number of degrees of freedom of the Wishart prior for the covariance of node coordinates; the default is \code{d}, the dimension of \code{S}.
 \item \code{W0} a \code{d times d} matrix specifying the matrix of the Wishart prior for the covariance of node coordinates; the default is \code{R0/d}.
}}

\item{GP.settings}{a list specifying the Gaussian process settings:
\itemize{
 \item \code{nu} smoothness parameter of the Matern kernel; the default is 2.5.
 \item \code{g} nugget; the default is \code{sqrt(.Machine$double.eps)}
 \item \code{theta.init} initial value of the lengthscale parameter for L-BFGS-B of \code{\link[stats]{optim}}; the default is 0.1. 
 \item \code{theta.lower} lower bound of the lengthscale parameter for L-BFGS-B of \code{\link[stats]{optim}}; the default is \code{sqrt(.Machine$double.eps)}. 
 \item \code{theta.upper} upper bound of the lengthscale parameter for L-BFGS-B of \code{\link[stats]{optim}}; the default is 100. 
}}

\item{parallel}{logical. If \code{TRUE}, parallel computing is conducted; the default is \code{FALSE}.}

\item{n.cores}{integer. If \code{parallel=TRUE}, it specifies how many cores will be used for parallel computing; the default is \code{\link[parallelly]{availableCores}}}

\item{trace}{logical. If \code{TRUE}, the computation time of each step will be printed; the default is \code{FALSE}.}
}
\description{
mcGP: mesh-clustered Gaussian process emulator for partial differential equation systems
}
\examples{
\dontrun{
library(mcGP)
set.seed(1)

##### setting #####
# example: Poisson equation simulations 
# (data was generated by finite element methods via MATLAB)
data(poisson_dat)
attach(poisson_dat)

print(dim(X)) # sample size is 5; one input variable
print(dim(S)) # 2-dimensional mesh; 401 mesh nodes
print(dim(Y)) # sample size is 5; 401 outputs at mesh nodes

# visualize two training examples
pde.plot <- function(u, nodes, ...){
  out <- as.image(u, x = nodes, nrow=128, ncol=128)
  dx <- out$x[2] - out$x[1] 
  dy <- out$y[2] - out$y[1] 
  out <- image.smooth(out$z, dx=dx, dy=dy, theta=.25) 
  image.plot(x = out$x, y = out$y, z = out$z, ...)
}

par(mfrow=c(1,2))
pde.plot(Y[,1], S, main=paste("x =", X[1,1]))
pde.plot(Y[,5], S, main=paste("x =", X[5,1]))

# model fitting
fit <- mcGP(X,Y,S)
print(fit$time.elapsed) # the time elapsed

# model fitting (with parallel computing)
fit <- mcGP(X,Y,S, parallel=TRUE)
print(fit$time.elapsed) # the time elapsed
}
}
\seealso{
\code{\link[mcGP]{predict.mcGP}} for predictions.
}
